{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AIVL8APUrj-"
      },
      "source": [
        "# PREDICTING WINE QUALITY WITH RANDOM FOREST AND SCIKIT-LEARN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMcWH0l5UrkA"
      },
      "source": [
        "## Task 1. Getting Started and Working with Google Colaboratory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqtYtSoLUrkA"
      },
      "source": [
        "- Rhyme: Coursera's hands-on project platform  \n",
        "- Virtual Browser  \n",
        "- Google Colaboratory: write and execute Python code in a Jupyter Notebook  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ93RNYzUrkB"
      },
      "source": [
        "## Task 2. Defining Problem, Importing Libraries and Downloading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDdE7Gt4UrkB"
      },
      "source": [
        "### 2.1 Define Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i6t0NNuUrkB"
      },
      "source": [
        "**Objective:** Modeling Wine Quality based on its physicochemical attributes.  \n",
        "\n",
        "**List of attributes:**\n",
        "- fixed acidity  \n",
        "- volatile acidity  \n",
        "- citric acid\n",
        "- residual sugar\n",
        "- chlorides\n",
        "- free sulfur dioxide\n",
        "- total sulfur dioxide\n",
        "- density\n",
        "- pH\n",
        "- sulphates\n",
        "- alcohol   \n",
        "\n",
        "**Quality:** Categorical levels from 3 to 8.\n",
        "\n",
        "**Data:**\n",
        "- There are two datasets related to red and white variants of the Portuguese \"Vinho Verde\" wine.\n",
        "- In this project we only use red wine dataset.\n",
        "- Datasets are available at [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/wine+quality) and [Paulo Cortez's web page](http://www3.dsi.uminho.pt/pcortez/wine/).    \n",
        "\n",
        "**Acknowledgements:**   \n",
        "Thanks for the assistance I received by using the *UCI Machine Learning Repository*.  \n",
        "Dua, D. and Graff, C. (2019). [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science.\n",
        "\n",
        "**Relevant paper:**  \n",
        "[1] P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. *Modeling wine preferences by data mining from physicochemical properties*. In Decision Support Systems, Elsevier, 47(4):547-553, 2009. Available [here](http://dx.doi.org/10.1016/j.dss.2009.05.016)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-XzcH26UrkC"
      },
      "source": [
        "### 2.2 Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZX0O2qfUrkC",
        "outputId": "d6d36608-9eb0-4d30-e953-173ab42cc02d"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd               # package for data analysis and manipulation\n",
        "import numpy as np                # package for scientific computing on multidimensional arrays\n",
        "import matplotlib                 # package for creating visualizations\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns             # data visualization library based on matplotlib\n",
        "import sklearn                    # machine learning library\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import tree\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "import scipy                      # library for mathematics, science and engineering\n",
        "from scipy.stats import spearmanr\n",
        "from scipy.cluster import hierarchy\n",
        "import collections\n",
        "import zipfile\n",
        "import requests\n",
        "import platform\n",
        "\n",
        "# Check Python version\n",
        "print('Python', platform.python_version())\n",
        "\n",
        "# Check the version of packages\n",
        "for package in [pd, np, matplotlib, sns, sklearn, scipy, requests, platform]:\n",
        "    print (package.__name__, package.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n",
            "pandas 1.1.5\n",
            "numpy 1.19.5\n",
            "matplotlib 3.2.2\n",
            "seaborn 0.11.1\n",
            "sklearn 0.22.2.post1\n",
            "scipy 1.4.1\n",
            "requests 2.23.0\n",
            "platform 1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daDO4_4pUrkD"
      },
      "source": [
        "# Remove the max column restriction for displaying on the screen\n",
        "pd.options.display.max_columns = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjTZ0aIIUrkD"
      },
      "source": [
        "### 2.3 Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ni6Yml4UrkE"
      },
      "source": [
        "url1 = 'http://www3.dsi.uminho.pt/pcortez/wine/winequality.zip'\n",
        "url2 = 'https://drive.google.com/uc?id=1dAb2OalBSblCop9UbGjiv9qnS3N-3Kuw'\n",
        "file = 'raw_data.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imfph-CHUrkE",
        "outputId": "3171ecd3-4fea-4d08-efcb-8c862c1343d9"
      },
      "source": [
        "try:\n",
        "    with requests.Session() as s:\n",
        "        response = s.get(url1)\n",
        "    open(file, 'wb').write(response.content)\n",
        "    print('Sucessful download from url 1\\n')\n",
        "except:\n",
        "    with requests.Session() as s:\n",
        "        response = s.get(url2)\n",
        "    open(file, 'wb').write(response.content)\n",
        "    print('Sucessful download from url 2\\n')\n",
        "\n",
        "zip_file = zipfile.ZipFile(file, mode='r')\n",
        "zip_file.printdir()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sucessful download from url 1\n",
            "\n",
            "File Name                                             Modified             Size\n",
            "winequality/winequality-names.txt              2009-10-07 15:52:54         2838\n",
            "winequality/winequality-names.txt.bak          2009-10-07 15:52:28         2838\n",
            "winequality/winequality-red.csv                2009-06-26 17:45:52        84199\n",
            "winequality/winequality-white.csv              2009-06-26 17:47:46       264426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op0JXfQTUrkE",
        "outputId": "a9c0a930-cef2-4849-dbb2-64b2c169f818"
      },
      "source": [
        "path = 'winequality/winequality-red.csv'\n",
        "\n",
        "wine_csv = zip_file.open(path, mode='r')\n",
        "\n",
        "# print some lines of red wine file\n",
        "wine_csv.readlines(300)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'\"fixed acidity\";\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"\\n',\n",
              " b'7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5\\n',\n",
              " b'7.8;0.88;0;2.6;0.098;25;67;0.9968;3.2;0.68;9.8;5\\n',\n",
              " b'7.8;0.76;0.04;2.3;0.092;15;54;0.997;3.26;0.65;9.8;5\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DQ2yJRhUrkE"
      },
      "source": [
        "wine_csv.seek(0)\n",
        "wine = pd.read_csv(wine_csv, sep=';')\n",
        "wine_csv.close()\n",
        "\n",
        "print('Shape of wine =', wine.shape)\n",
        "print('Number of rows = {}, Number of columns = {}'.format(wine.shape[0], wine.shape[1]))\n",
        "wine.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiAsO77zUrkF"
      },
      "source": [
        "## Task 3. Cleaning Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLexQy_tUrkF"
      },
      "source": [
        "### 3.1 Rename and change the order of columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKU__yiVUrkF"
      },
      "source": [
        "wine.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUF8OXcIUrkF"
      },
      "source": [
        "wine.columns = wine.columns.str.replace(' ', '_')\n",
        "wine.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD-xKsi3UrkF"
      },
      "source": [
        "wine.columns.get_loc('quality'), wine.columns.get_loc('alcohol')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhmtOm6sUrkG"
      },
      "source": [
        "new_order = [11, 10] + list(range(10))\n",
        "wine = wine[wine.columns[new_order]]\n",
        "wine.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hSyIPZYUrkG"
      },
      "source": [
        "### 3.2 Remove duplicates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Wx7DvQUrkG"
      },
      "source": [
        "print('Number of row before removing duplicates =', wine.shape[0])\n",
        "print('Duplicated rows:\\n', wine.duplicated())\n",
        "print('Number of duplicated rows =', wine.duplicated().sum())\n",
        "wine.drop_duplicates(inplace=True)\n",
        "wine.reset_index(drop=True, inplace=True)\n",
        "print('Number of rows after removing duplicates =', len(wine))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt2X9pnzUrkG"
      },
      "source": [
        "wine_2 = wine.copy()\n",
        "wine_2.drop('quality', axis=1, inplace=True)\n",
        "print('Number of duplicated rows =', wine_2.duplicated().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGY47qFyUrkH"
      },
      "source": [
        "### 3.3 Save .csv file to disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHlb1FSuUrkH"
      },
      "source": [
        "wine.to_csv('red_wine.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8orpp1CmUrkH"
      },
      "source": [
        "## Task 4. Performing Exploratory Data Analysis (part 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZkZyhvfUrkH"
      },
      "source": [
        "### 4.1 Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcItvoHOUrkH"
      },
      "source": [
        "print('Number of rows = {}, Number of columns = {}'.format(wine.shape[0], wine.shape[1]))\n",
        "wine.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5RPhyuPUrkH"
      },
      "source": [
        "wine.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFBb7CbIUrkI"
      },
      "source": [
        "wine.isna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo_exqYCUrkI"
      },
      "source": [
        "wine.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkh_h268UrkI"
      },
      "source": [
        "wine.isna().sum().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM2esp6UUrkI"
      },
      "source": [
        "wine['quality'].value_counts(sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoL2gj8IUrkI"
      },
      "source": [
        "wine.quality.value_counts(sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F99PpuMyUrkI"
      },
      "source": [
        "wine.quality.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOiuCY1PUrkJ"
      },
      "source": [
        "wine.groupby('quality').quality.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdBrEG7BUrkJ"
      },
      "source": [
        "wine.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNy0wN62UrkJ"
      },
      "source": [
        "### 4.2 Histogram of wine quality with 6 classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc4xm3iDUrkJ"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=17aLzn7xqB0hImTWoLpl2H1PYV5rc8FIw'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBaRl4sBUrkJ"
      },
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "ax = sns.countplot(x='quality', data=wine, color='green')\n",
        "ax.set(title='HISTOGRAM OF WINE QUALITY', xlabel='', ylabel='', yticklabels=[])\n",
        "ax.tick_params(left=False)\n",
        "ax.set_ylim(0, 650)\n",
        "for p in ax.patches:\n",
        "    ax.annotate(p.get_height(),\n",
        "                xy=(p.get_x() + p.get_width() / 2, p.get_height()),\n",
        "                xytext = (0, 10),\n",
        "                textcoords = 'offset points',\n",
        "                ha = 'center',\n",
        "                size=10)\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJi0KWIFUrkJ"
      },
      "source": [
        "## Task 5. Performing Exploratory Data Analysis (part 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3DZ9HNWUrkJ"
      },
      "source": [
        "### 5.1 Histogram of wine quality with 2 classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gc1RqfKUrkK"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=158QRa9gvLM_xHrBybPysyCtduLMLIy5D'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwFPshLMUrkK"
      },
      "source": [
        "category_dic = {3:'bad', 4:'bad', 5:'bad', 6:'good', 7:'good', 8:'good'}\n",
        "wine['quality2'] = wine.quality.map(category_dic)\n",
        "\n",
        "wine.quality2.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKbN3jXTUrkK"
      },
      "source": [
        "np.round(wine.quality2.value_counts() / len(wine) * 100, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwLkcmLyUrkK"
      },
      "source": [
        "class_labels = ['bad', 'good'] # class labels for graphs\n",
        "custom_palette = {'bad':'blue', 'good':'red',\n",
        "                 0:'blue', 1:'red'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmfHggmSUrkK"
      },
      "source": [
        "plt.figure(figsize=(3.5, 4))\n",
        "\n",
        "ax = sns.countplot(x='quality2', data=wine, palette=custom_palette)\n",
        "ax.set(title='HISTOGRAM OF WINE QUALITY', xlabel='', ylabel='', yticklabels=[])\n",
        "ax.tick_params(left=False)\n",
        "ax.set_ylim(0, 810)\n",
        "for p in ax.patches:\n",
        "    ax.annotate(p.get_height(),\n",
        "                xy=(p.get_x() + p.get_width() / 2, p.get_height()),\n",
        "                xytext = (0, 10),\n",
        "                textcoords = 'offset points',\n",
        "                ha = 'center',\n",
        "                size=10)\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-vgOeEiUrkK"
      },
      "source": [
        "### 5.2 Violin plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt7HFaPFUrkK"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1Ki4H99G52hLGVMa63jJnAPTgLp7z8d_U'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePoA6wooUrkL"
      },
      "source": [
        "fig, axs = plt.subplots(4, 3, figsize=(12, 10))\n",
        "fig.suptitle('VIOLIN PLOTS', fontsize=15)\n",
        "\n",
        "column_names = wine.columns[1:12]\n",
        "for i, column_name in enumerate(column_names):\n",
        "    sns.violinplot(x='quality2', y=column_name, data=wine, ax=axs[i//3][i%3], palette=custom_palette)\n",
        "\n",
        "axs[3][2].axis('off')\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.93)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voMguMSFUrkL"
      },
      "source": [
        "### 5.3 Correlation plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laPv5e6DUrkL"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1FQ4m4nP2l9PfmhtSFXqlY6BTYSJWa8ec'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYu7i__XUrkL"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,6.5))\n",
        "\n",
        "pearson_corr = wine.iloc[:,1:12].corr(method='pearson')\n",
        "spearman_corr = wine.iloc[:,1:12].corr(method='spearman')\n",
        "\n",
        "mask = np.triu(np.ones_like(pearson_corr, dtype=bool), k=0)\n",
        "cmap = sns.diverging_palette(150, 275)\n",
        "\n",
        "sns.heatmap(pearson_corr, mask=mask, annot=True, fmt=',.2f', cmap=cmap,\n",
        "            cbar=True, cbar_kws={\"shrink\": .5}, square=True, linewidths=.5,\n",
        "            vmax=0.8, vmin=-0.8, center=0, ax=ax1)\n",
        "ax1.set_title('PEARSON CORRELATION MATRIX')\n",
        "\n",
        "sns.heatmap(spearman_corr, mask=mask, annot=True, fmt=',.2f', cmap=cmap,\n",
        "            cbar=False, square=True, linewidths=.5,\n",
        "            vmax=0.8, vmin=-0.8, center=0, ax=ax2)\n",
        "ax2.set_title('SPEARMAN CORRELATION MATRIX')\n",
        "\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO56Rk_PUrkL"
      },
      "source": [
        "## Task 6. Generating Training, Validation and Testing Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td0LBp-uUrkL"
      },
      "source": [
        "### 6.1 Define feature dataset and encode class labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS5lkvduUrkM"
      },
      "source": [
        "X = wine.iloc[:,1:12]\n",
        "\n",
        "y = LabelEncoder().fit_transform(wine.quality2)\n",
        "np.unique(y, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxjaDK6IUrkM"
      },
      "source": [
        "class_dictionary = {'bad':0, 'good':1}\n",
        "y = wine.quality2.map(class_dictionary)\n",
        "y.value_counts(sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47B0Y9PJUrkM"
      },
      "source": [
        "feature_names = np.array(X.columns)\n",
        "print('Number of features =', len(feature_names))\n",
        "print(feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIcKdUmHUrkM"
      },
      "source": [
        "### 6.2 Generate training, validation and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alp-T_BJUrkM"
      },
      "source": [
        "# X_train - X_val - X_test\n",
        "# 40 - 40 - 20\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2**9, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.50, random_state=9**2, stratify=y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-EbvS-5UrkM"
      },
      "source": [
        "print('Number of rows: y_train:{}, y_val:{}, y_test:{}, Total:{}'.format(len(y_train), len(y_val), len(y_test), len(y)))\n",
        "\n",
        "print('\\nDistribution by classes:')\n",
        "pd.DataFrame({'train set':np.unique(y_train, return_counts=True)[1],\n",
        "              'validation set': np.unique(y_val, return_counts=True)[1],\n",
        "              'test set': np.unique(y_test, return_counts=True)[1]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNsQIZg5UrkN"
      },
      "source": [
        "## Task 7. Creating a Data Visualizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrGOzPA3UrkN"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1hJ2zJyv-WCvM8d5dxo1uooO3xJKBgNM3'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEPDKXelUrkN"
      },
      "source": [
        "def print_outputs(X, X_train, X_val, X_test, y, y_train, y_val, y_test, clf,\n",
        "                 title='CONFUSION MATRICES'):\n",
        "\n",
        "    train_score = clf.score(X_train, y_train)\n",
        "    val_score = clf.score(X_val, y_val)\n",
        "    test_score = clf.score(X_test, y_test)\n",
        "\n",
        "    print('   - Accuracy on training set = {:.2f}'.format(train_score))\n",
        "    print('   - Accuracy on validation set = {:.2f}'.format(val_score))\n",
        "    print('   - Accuracy on testing set = {:.2f}'.format(test_score))\n",
        "    print('   - Total Accuracy = {:.2f}\\n'.format(clf.score(X, y)))\n",
        "\n",
        "    y_train_predicted = clf.predict(X_train)\n",
        "    y_val_predicted = clf.predict(X_val)\n",
        "    y_test_predicted = clf.predict(X_test)\n",
        "\n",
        "    confusion = []\n",
        "    confusion.append(pd.DataFrame(confusion_matrix(y_train, y_train_predicted))) # train\n",
        "    confusion.append(pd.DataFrame(confusion_matrix(y_val, y_val_predicted))) # validation\n",
        "    confusion.append(pd.DataFrame(confusion_matrix(y_test, y_test_predicted))) # test\n",
        "\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 3))\n",
        "    fig.suptitle(title, fontsize=15)\n",
        "    axs = [ax1, ax2, ax3]\n",
        "\n",
        "    for i in range(3):\n",
        "        sns.heatmap(confusion[i], annot=True, fmt=',.0f', cbar=False, cmap='YlGnBu', ax= axs[i])\n",
        "        axs[i].set(xticklabels=class_labels, yticklabels=class_labels, xlabel='Predicted label', ylabel='True label')\n",
        "\n",
        "    ax1.set_title('Training accuracy = {:.2f}'.format(train_score))\n",
        "    ax2.set_title('Validation accuracy = {:.2f}'.format(val_score))\n",
        "    ax3.set_title('Testing accuracy = {:.2f}'.format(test_score))\n",
        "\n",
        "    fig.tight_layout()\n",
        "    fig.subplots_adjust(top=0.80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLGJQzNpUrkN"
      },
      "source": [
        "## Task 8. Applying a Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBKNBzT6UrkN"
      },
      "source": [
        "### 8.1 Train classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2VJeCfaUrkO"
      },
      "source": [
        "clf_0 = RandomForestClassifier(random_state=0)\n",
        "clf_0.fit(X_train, y_train)\n",
        "\n",
        "print_outputs(X, X_train, X_val, X_test, y, y_train, y_val, y_test, clf_0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEBh-caSUrkO"
      },
      "source": [
        "### 8.2 Calibrate classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3ymvEJCUrkO"
      },
      "source": [
        "clf_0c = CalibratedClassifierCV(clf_0, method='sigmoid', cv='prefit')\n",
        "clf_0c.fit(X_val, y_val)\n",
        "\n",
        "print_outputs(X, X_train, X_val, X_test, y, y_train, y_val, y_test, clf_0c, title='CONFUSION MATRICES AFTER CALIBRATING')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWetF8oLUrkO"
      },
      "source": [
        "### 8.3 Swap roles between training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgkc3j_RUrkO"
      },
      "source": [
        "print('Training classifier before clalibrating:')\n",
        "clf_1 = RandomForestClassifier(random_state=0)\n",
        "clf_1.fit(X_val, y_val)\n",
        "print_outputs(X, X_val, X_train, X_test, y, y_val, y_train, y_test, clf_1, title='CONFUSION MATRICES BEFORE CALIBRATING')\n",
        "\n",
        "print('Training classifier after calibrating:')\n",
        "clf_1c = CalibratedClassifierCV(clf_1, method='sigmoid', cv='prefit')\n",
        "clf_1c.fit(X_train, y_train)\n",
        "print_outputs(X, X_val, X_train, X_test, y, y_val, y_train, y_test, clf_1c, title='CONFUSION MATRICES AFTER CALIBRATING')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVzXuiouUrkO"
      },
      "source": [
        "## Task 9. Analizing Random Forest Importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brxVSv8YUrkP"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1qCto36Zuzw-U0tUSyQrj_1R2Yqgd2RNb'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6dTyPukUrkP"
      },
      "source": [
        "# clf_0 = RandomForestClassifier(random_state=0)\n",
        "# clf_0.fit(X_train, y_train)\n",
        "\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "fig.suptitle('RANDOM FOREST IMPORTANCES', fontsize=15)\n",
        "\n",
        "feature_importances = clf_0.feature_importances_\n",
        "sorted_idx = feature_importances.argsort()\n",
        "\n",
        "y_ticks = np.arange(0, len(feature_names))\n",
        "ax1.barh(y_ticks, feature_importances[sorted_idx], color='blue', alpha=0.8)\n",
        "ax1.set_yticklabels(feature_names[sorted_idx])\n",
        "ax1.set_yticks(y_ticks)\n",
        "ax1.set_title(\"FEATURE IMPORTANCES (MDI) ON TRAINING SET\")\n",
        "\n",
        "permutation_train = permutation_importance(clf_0, X_train, y_train, n_repeats=15, random_state=7**4, n_jobs=-1)\n",
        "sorted_idx = permutation_train.importances_mean.argsort()\n",
        "#print(permutation_train.importances_mean[sorted_idx].T)\n",
        "ax2.boxplot(permutation_train.importances[sorted_idx].T,\n",
        "           vert=False, labels=feature_names[sorted_idx])\n",
        "ax2.set_title('PERMUTATION IMPORTANCES ON TRAINING SET')\n",
        "\n",
        "ax3.axis('off')\n",
        "\n",
        "permutation_val = permutation_importance(clf_0, X_val, y_val, n_repeats=15, random_state=6**3, n_jobs=-1)\n",
        "sorted_idx = permutation_val.importances_mean.argsort()\n",
        "\n",
        "ax4.boxplot(permutation_val.importances[sorted_idx].T,\n",
        "           vert=False, labels=feature_names[sorted_idx])\n",
        "\n",
        "ax4.set_title('PERMUTATION IMPORTANCES ON VALIDATION SET')\n",
        "\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.92)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRYTRJNdUrkP"
      },
      "source": [
        "## Task 10. Clustering Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvkPgPnyUrkP"
      },
      "source": [
        "### 10.1 Compute Ward's minimum variance criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLN1Jjw-UrkP"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1AoCPSURgQAttSHkRdzvnO_rMEKR52Lzw'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeAgJZ2sUrkP"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6.5))\n",
        "corr = spearmanr(X_train).correlation\n",
        "corr_linkage = hierarchy.ward(corr)\n",
        "dendro = hierarchy.dendrogram(\n",
        "    corr_linkage, labels=feature_names, ax=ax1, leaf_rotation=90)\n",
        "ax1.set_title('DENDROGRAM FOR TRAINING SET')\n",
        "ax1.axhline(1, color='cyan')\n",
        "\n",
        "corr_dendro = corr[dendro['leaves'], :][:, dendro['leaves']] #  cluster node j appears in position i in the left-to-right traversal of the leaves\n",
        "mask = np.triu(np.ones_like(corr_dendro, dtype=bool), k=0) # Generate a mask for the upper triangle\n",
        "\n",
        "sns.heatmap(corr_dendro, mask=mask, annot=True, fmt=',.2f', cmap=cmap,\n",
        "            cbar=True, cbar_kws={\"shrink\": .5}, square=True, linewidths=.5,\n",
        "            center=0, vmax=0.8, vmin=-0.8, ax=ax2)\n",
        "\n",
        "ax2.set_title('CORRELATION MATRIX ON TRAINING SET (SPEARMAN)')\n",
        "ax2.set_xticklabels(dendro['ivl'], rotation=90)\n",
        "ax2.set_yticklabels(dendro['ivl'], rotation=0)\n",
        "\n",
        "fig.tight_layout();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szr3qpZeUrkP"
      },
      "source": [
        "### 10.2 Select features from clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJQSMAfdUrkQ"
      },
      "source": [
        "cluster_ids = hierarchy.fcluster(corr_linkage, t=1, criterion='distance')\n",
        "the_dict = collections.defaultdict(list) #defaultdict is created with the values that are list.\n",
        "for idx, cluster_id in enumerate(cluster_ids):\n",
        "    the_dict[cluster_id].append(idx)\n",
        "selected_features = [v[0] for v in the_dict.values()]\n",
        "removed_features = [i for i in range(len(feature_names)) if i not in selected_features]\n",
        "#removed_features = list(set(feature_names) - set(feature_names[selected_features]))\n",
        "\n",
        "print('Number of selected features =', len(selected_features))\n",
        "print('Selected features =', feature_names[selected_features].tolist())\n",
        "print('Removed features =', feature_names[removed_features].tolist(), '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgjU3qgsUrkQ"
      },
      "source": [
        "### 10.3 Train classifier with selected features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCPAZWF5UrkQ"
      },
      "source": [
        "X_sel = X.iloc[:, selected_features]\n",
        "X_train_sel = X_train.iloc[:, selected_features]\n",
        "X_val_sel = X_val.iloc[:, selected_features]\n",
        "X_test_sel = X_test.iloc[:, selected_features]\n",
        "\n",
        "print('Training classifier before calibrating:')\n",
        "clf_2 = RandomForestClassifier(random_state=0)\n",
        "clf_2.fit(X_train_sel, y_train)\n",
        "print_outputs(X_sel, X_train_sel, X_val_sel, X_test_sel, y, y_train, y_val, y_test, clf_2,\n",
        "             title='CONFUSION MATRICES FOR SELECTED FEATURES BEFORE CALIBRATING')\n",
        "\n",
        "print('Training classifier after calibrating:')\n",
        "clf_2c = CalibratedClassifierCV(clf_2, method='sigmoid', cv='prefit')\n",
        "clf_2c.fit(X_val_sel, y_val)\n",
        "print_outputs(X_sel, X_train_sel, X_val_sel, X_test_sel, y, y_train, y_val, y_test, clf_2c,\n",
        "             title='CONFUSION MATRICES FOR SELECTED FEATURES AFTER CALIBRATING')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqXoBRoiUrkQ"
      },
      "source": [
        "### 10.4 Train classifier with removed features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2bOCHm1UrkQ"
      },
      "source": [
        "X_rem = X.iloc[:, removed_features]\n",
        "X_train_rem = X_train.iloc[:, removed_features]\n",
        "X_val_rem = X_val.iloc[:, removed_features]\n",
        "X_test_rem = X_test.iloc[:, removed_features]\n",
        "\n",
        "print('Training classifier before calibrating:')\n",
        "clf_3 = RandomForestClassifier(random_state=0)\n",
        "clf_3.fit(X_train_rem, y_train)\n",
        "print_outputs(X_rem, X_train_rem, X_val_rem, X_test_rem, y, y_train, y_val, y_test, clf_3,\n",
        "             title='CONFUSION MATRICES FOR REMOVED FEATURES BEFORE CALIBRATING')\n",
        "\n",
        "print('Training classifier after calibrating:')\n",
        "clf_3c = CalibratedClassifierCV(clf_3, method='sigmoid', cv='prefit')\n",
        "clf_3c.fit(X_val_rem, y_val)\n",
        "print_outputs(X_rem, X_train_rem, X_val_rem, X_test_rem, y, y_train, y_val, y_test, clf_3c,\n",
        "             title='CONFUSION MATRICES FOR REMOVED FEATURES AFTER CALIBRATING')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HRRDVxEUrkQ"
      },
      "source": [
        "## Task 11. Performing Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CtCRxeqUrkQ"
      },
      "source": [
        "param_grid = {\n",
        "    'n_estimators' : [50, 75, 100],    # The number of trees in the forest, default=100\n",
        "    'max_features' : [2, 5],           # The number of features to consider when looking for the best split, default=sqrt(n_features)\n",
        "    'max_depth'    : [3, 5, 7],        # The maximum depth of the tree, default=None\n",
        "    'class_weight' : [None, 'balanced', 'balanced_subsample'] # Used to associate weights with classes, default=None\n",
        "}\n",
        "\n",
        "X_train_2 = pd.concat([X_train_sel, X_val_sel], ignore_index=True)\n",
        "y_train_2 = pd.concat([y_train, y_val], ignore_index=True)\n",
        "\n",
        "clf_4 = RandomForestClassifier(random_state=0)\n",
        "skf = StratifiedKFold(n_splits=3, random_state=5**5, shuffle=True)\n",
        "clf_grid = GridSearchCV(clf_4, param_grid, cv=skf, n_jobs=-1)\n",
        "clf_grid.fit(X_train_2, y_train_2)\n",
        "print('Best parameters found by grid search are:\\n', clf_grid.best_params_)\n",
        "print('\\nBest cross validation score =', clf_grid.best_score_)\n",
        "\n",
        "print_outputs(X_sel, X_train_2, X_train_2, X_test_sel, y, y_train_2, y_train_2, y_test, clf_grid.best_estimator_,\n",
        "                 title='CONFUSION MATRICES FOR SELECTED FEATURES WITH HYPERPARAMETER TUNING')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUgHnJeyUrkR"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGZi3wJoUrkR"
      },
      "source": [
        "## **Further Readings:**   \n",
        "- *4 Types of Classification Tasks in Machine Learning*. Available [here](https://machinelearningmastery.com/types-of-classification-in-machine-learning/).    \n",
        "- *A comparison of the Pearson and Spearman correlation methods*. Available [here](https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/supporting-topics/basics/a-comparison-of-the-pearson-and-spearman-correlation-methods/#:~:text=The%20Pearson%20correlation%20evaluates%20the%20linear%20relationship%20between%20two%20continuous%20variables.&text=The%20Spearman%20correlation%20coefficient%20is,evaluate%20relationships%20involving%20ordinal%20variables).        \n",
        "- *Beware Default Random Forest Importances*. Available [here](https://explained.ai/rf-importance/).          "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2ftTwtZUrkR"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}